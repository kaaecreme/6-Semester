{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Own Linear Regressesor\n",
    "\n",
    "Create a linear regressor, with a Scikit-learn compatible fit-predict interface. You should implement every detail of the linear regressor in Python, using whatever library you want (except a linear regressor itself).\n",
    "\n",
    "You must investigate and describe all major details for a linear regressor, and implement at least the following concepts (MUST):\n",
    "\n",
    "### Qa: Concepts and Implementations MUSTS\n",
    "\n",
    "* the `fit-predict` interface, and a $R^2$ score function,\n",
    "* one-dimensional output only,\n",
    "* loss function based on (R)MSE,\n",
    "* setting of the number of iterations and learning rate ($\\eta$) via parameters in the constructor, the signature of your `__init__` must include the named parameters `max_iter` and `eta0`,\n",
    "* the batch-gradient decent algorithm (GD),\n",
    "* constant or adaptive learning rate,\n",
    "* learning graphs,\n",
    "* stochastic gradient descent (SGD),\n",
    "* epochs vs iteations,\n",
    "* compare the numerical optimization with the Closed-form solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class MyLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, max_iter=1000, eta0=0.01):\n",
    "        self.max_iter = max_iter # Number of iterations\n",
    "        self.eta0 = eta0 # Learning rate\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y_true):\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)  # Initialize weights with zeros\n",
    "        self.bias = 0  # Initialize bias with zero\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "        # Calculate predictions\n",
    "            y_pred = self.predict(X)\n",
    "\n",
    "            # Calculate errors\n",
    "            errors = y_pred - y_true\n",
    "\n",
    "            # Update weights and bias using gradient descent\n",
    "            self.weights -= self.eta0 * (1/m) * np.dot(X.T, errors)\n",
    "            self.bias -= self.eta0 * (1/m) * np.sum(errors)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return r2_score(y, self.predict(X))\n",
    "\n",
    "    def RMSE(self, y_pred, y_true):\n",
    "        # Calculate squared differences (L2)\n",
    "        squared_diff = (y_true - y_pred) ** 2\n",
    "        \n",
    "        # Compute mean of squared differences\n",
    "        mean_squared_diff = np.mean(squared_diff)\n",
    "        \n",
    "        # Take square root to obtain RMSE\n",
    "        rmse_value = np.sqrt(mean_squared_diff)\n",
    "        \n",
    "        return rmse_value\n",
    "    \n",
    "    # From our own previous assignment\n",
    "    def checkInputSameShape(self, y_pred, y_true):\n",
    "        assert y_pred.shape == y_true.shape, \"Shape of input is not equal!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING: This mini smoke test is currently untested, please modify...\u001b[0m\n",
      "\u001b[1;35my_pred = [5.61498304 6.75547481 4.04730809 5.18372265]\u001b[0m\n",
      "\u001b[1;35mSCORE = 0.49500564295554395\u001b[0m\n",
      "\u001b[1;35mbias         = 4.046878010107266\u001b[0m\n",
      "\u001b[1;35mcoefficients = [1.88012265]\u001b[0m\n",
      "\tw         =[4.046878010107 1.880122650194]\n",
      "\tw_expected=[4.046879011698 1.880121487278]\n",
      "\u001b[1;35mwell, good news, your w and the expected w-vector seem to be very close numerically, so the smoke-test has passed!\u001b[0m\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Mini smoke test for your linear regressor...\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "def PrintOutput(msg, pre_msg, ex=None, color=\"\", filestream=sys.stdout):\n",
    "    #BLACK    =\"\\033[0;30m\"\n",
    "    #BLUE     =\"\\033[0;34m\"\n",
    "    #LBLUE    =\"\\033[1;34m\"\n",
    "    #RED      =\"\\033[0;31m\"\n",
    "    #LRED     =\"\\033[1;31m\"\n",
    "    #GREEN    =\"\\033[0;32m\"\n",
    "    #LGREEN   =\"\\033[1;32m\"\n",
    "    #YELLOW   =\"\\033[0;33m\"\n",
    "    #LYELLOW  =\"\\033[1;33m\"\n",
    "    #PURPLE   =\"\\033[0;35m\"\n",
    "    #LPURPLE  =\"\\033[1;35m\"\n",
    "    #CYAN     =\"\\033[0;36m\"\n",
    "    #LCYAN    =\"\\033[1;36m\"\n",
    "    #BROWN    =\"\\033[0;33m\"\n",
    "    #DGRAY    =\"\\033[1;30m\"\n",
    "    #LGRAY    =\"\\033[0;37m\"\n",
    "    #WHITE    =\"\\033[1;37m\"\n",
    "    #NC       =\"\\033[0m\"\n",
    "    color_end = \"\\033[0m\" if color!=\"\" else \"\"\n",
    "    if ex is not None:\n",
    "        msg += f\"\\n   EXCEPTION: {ex} ({type(ex)})\"\n",
    "    print(f\"{color}{pre_msg}{msg}{color_end}\", file=filestream)\n",
    "\n",
    "def Warn(msg, ex=None):\n",
    "    PrintOutput(msg, \"WARNING: \", ex, \"\\033[1;33m\")\n",
    "\n",
    "def Err(msg, ex=None):\n",
    "    PrintOutput(msg, \"ERROR: \", ex, \"\\033[1;31m\" )\n",
    "    exit(-1)\n",
    "\n",
    "def Info(msg):\n",
    "    PrintOutput(msg, \"\", None, \"\\033[1;35m\")\n",
    "\n",
    "def SimplePrintMatrix(x, label=\"\", precision=12):\n",
    "    # default simple implementation, may be overwritten by a libitmal function later..\n",
    "    print(f\"{label}{' ' if len(label)>0 else ''}{x}\")\n",
    "\n",
    "def SimpleAssertInRange(x, expected, eps):\n",
    "    #assert isinstance(x, numpy.ndarray)\n",
    "    #assert isinstance(expected, numpy.ndarray)\n",
    "    #assert x.ndim==1 and expected.ndim==1\n",
    "    #assert x.shape==expected.shape\n",
    "    assert eps>0\n",
    "    assert numpy.allclose(x, expected, eps) # should rtol or atol be set to eps?\n",
    "\n",
    "def GenerateData():\n",
    "    X = numpy.array([[8.34044009e-01],[1.44064899e+00],[2.28749635e-04],[6.04665145e-01]])\n",
    "    y = numpy.array([5.97396028, 7.24897834, 4.86609388, 3.51245674])\n",
    "    return X, y\n",
    "\n",
    "def TestMyLinReg():\n",
    "    X, y = GenerateData()\n",
    "\n",
    "    try:\n",
    "        # assume that your regressor class is named 'MyLinReg', please update/change\n",
    "        regressor = MyLinearRegressor()\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor has another name, than 'MyLinReg', please change the name in this smoke test\", ex)\n",
    "\n",
    "    try:\n",
    "        regressor = MyLinearRegressor(max_iter=200, eta0=0.4)\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor can not be constructed via the __init_ (with two parameters, see call above\", ex)\n",
    "\n",
    "    try:\n",
    "        regressor.fit(X, y)\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor can not fit\", ex)\n",
    "\n",
    "    try:\n",
    "        y_pred = regressor.predict(X)\n",
    "        Info(f\"y_pred = {y_pred}\")\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor can not predict\", ex)\n",
    "\n",
    "    try:\n",
    "        score  = regressor.score(X, y)\n",
    "        Info(f\"SCORE = {score}\")\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor fails in the score call\", ex)\n",
    "\n",
    "    try:\n",
    "        w    = None # default\n",
    "        bias = None # default\n",
    "        try:\n",
    "            w = regressor.weights\n",
    "            bias = regressor.bias\n",
    "        except Exception as ex:\n",
    "            w = None\n",
    "            Warn(\"your regressor has no coef_/intercept_ atrributes, trying Weights() instead..\", ex)\n",
    "        try:\n",
    "            if w is None:\n",
    "                w = regressor.Weights() # maybe a Weigths function is avalible on you model?\n",
    "                try:\n",
    "                    assert w.ndim == 1,     \"can only handle vector like w's for now\"\n",
    "                    assert w.shape[0] >= 2, \"expected length of to be at least 2, that is one bias one coefficient\"\n",
    "                    bias = w[0]\n",
    "                    w = w[1:]\n",
    "                except Exception as ex:\n",
    "                    w = None\n",
    "                    Err(\"having a hard time concantenating our bias and coefficients, giving up!\", ex)\n",
    "        except Exception as ex:\n",
    "            w = None\n",
    "            Err(\"your regressor also has no Weights() function, giving up!\", ex)\n",
    "        Info(f\"bias         = {bias}\")\n",
    "        Info(f\"coefficients = {w}\")\n",
    "    except Exception as ex:\n",
    "        Err(\"your regressor fails during extraction of bias and weights (but is a COULD)\", ex)\n",
    "\n",
    "    try:\n",
    "        from libitmal.utils import PrintMatrix\n",
    "    except Exception as ex:\n",
    "        PrintMatrix = SimplePrintMatrix # fall-back\n",
    "        Warn(\"could not import PrintMatrix from libitmal.utils, defaulting to simple function..\")\n",
    "\n",
    "    try:\n",
    "        from libitmal.utils import AssertInRange\n",
    "    except Exception as ex:\n",
    "        AssertInRange = SimpleAssertInRange # fall-back\n",
    "        Warn(\"could not import AssertInRange from libitmal.utils, defaulting to simple function..\")\n",
    "\n",
    "    try:\n",
    "        if w is not None:\n",
    "            if bias is not None:\n",
    "                w = numpy.concatenate(([bias], w)) # re-concat bias an coefficients, may be incorrect for your implementation!\n",
    "            # TEST VECTOR:\n",
    "            w_expected = numpy.array([4.046879011698, 1.880121487278])\n",
    "            PrintMatrix(w,          label=\"\\tw         =\", precision=12)\n",
    "            PrintMatrix(w_expected, label=\"\\tw_expected=\", precision=12)\n",
    "            eps = 1E-3 # somewhat big epsilon, allowing some slack..\n",
    "            AssertInRange(w, w_expected, eps)\n",
    "            Info(\"well, good news, your w and the expected w-vector seem to be very close numerically, so the smoke-test has passed!\")\n",
    "        else:\n",
    "            Warn(\"cannot test due to missing w information\")\n",
    "    except Exception as ex:\n",
    "        Err(\"mini-smoketest on your regressor failed\", ex)\n",
    "\n",
    "Warn(\"This mini smoke test is currently untested, please modify...\")\n",
    "TestMyLinReg()\n",
    "print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
