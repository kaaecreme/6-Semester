{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "\n",
    "Excercise 9 from [HOML], p.496 2nd./p.535 3rd. (slighty modified):\n",
    "\n",
    "__\"9. Build an CNN via the Keras API and try to achieve the highest possible accuracy on MNIST.\"__\n",
    "\n",
    "For the journal: \n",
    "\n",
    "* write an introduction to CNNs (what are CNNs, what is a convolution layer, etc..), \n",
    "* document your experiments towards the end-goal of reaching 'a high accuracy' (what did you try, what work/did not work), \n",
    "* document how you use '_generalization_' in your setup (us of simple hold-out/train-test split or k-fold, or etc..),\n",
    "* produce some sort of '_learning-curve_' that illustrates the drop in cost- or increase in score-function with respect to, say training iteration (for inspiration see fig 4.20, 10-12 or 10.17 in [HOML]),\n",
    "* document the final CNN setup (layers etc., perhaps as a graph/drawing), \n",
    "* discus on your iterations towards the end-goal and other findings you had,\n",
    "* and, as always, write a conclusion.\n",
    "\n",
    "If you use a code template from slides, HOML or the internet, then remember to add a reference to the original work in you journal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an introduction to CNNs (what are CNNs, what is a convolution layer, etc..):\n",
    "\n",
    "A convolutional nerual network (CNN) is a specific type of neural network (NN), \n",
    "designed for processing data like images. Whereas NN can be \"general-purpose\",\n",
    "the CNN is more focused on analzying grid-like data, which is what images are.\n",
    "Therefore the CNN would be prefered to use in cases like image classification,\n",
    "where you would label items in the image, and object detection in the image.\n",
    "\n",
    "Convolutional layer:\n",
    "A CNN consists of multiple layers where the convolutional layer is the building block of the CNN,\n",
    "and this layer is also where the neural network has its name from. \n",
    "This layer aplies different filters to the input data. Each of these filters can be described as a small matrix filled with weights,\n",
    "that moves across the data (like moving across a image) doing calculations at each of its positions, this operation is called convolution.\n",
    "The goal of these filters is to find features or patterns within the image. \n",
    "Examples of this can be edges of motives in the image, and later more complex things in the image, like shapes and recognizable parts of objects.\n",
    "\n",
    "Pooling layer:\n",
    "The pooling layers goal is to reduce the input data into small parts, therefor with images a small part will be a small group of pixels.\n",
    "The two most common technic of doing this is Max pooling or average pooling.\n",
    "The max pooling takes maximum values of the small part of the input data, \n",
    "where the average pooling takes the average value from the small part of the input data.\n",
    "\n",
    "Fully Connected layer:\n",
    "Lastly there is the fully connected layer, which combines the several layers of convolutional and pooling layers. \n",
    "Here the classification task is performed. \n",
    "\n",
    "\n",
    "---- FÃ˜LGENDE ER KOPIRET FRA GEMINI ---- \n",
    "Ved ikke om det er relevant...\n",
    "\n",
    "How CNNs Learn\n",
    "\n",
    "Feature Extraction: \n",
    "Convolutional and pooling layers work together to extract a hierarchy of features from the input image,\n",
    "going from simple to complex.\n",
    "\n",
    "Classification: \n",
    "Fully connected layers analyze these high-level features,\n",
    "ultimately predicting the class of the input image or the locations of objects within it.\n",
    "\n",
    "Backpropagation: \n",
    "Like other neural networks, CNNs learn through a process called backpropagation. \n",
    "This involves calculating the error between the predicted output and the correct label, \n",
    "and then adjusting the weights within the filters and all layers backwards through the network to minimize that error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1815947700.py, line 77)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[47], line 77\u001b[1;36m\u001b[0m\n\u001b[1;33m    def test_model()\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "class CNNModel(keras.callbacks.Callback):\n",
    "    def __init__(self) -> None:\n",
    "        # Gemini code\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
    "        \n",
    "        self.epoch_loss = None\n",
    "        self.epoch_accuracy = None\n",
    "        self.training_loss = None\n",
    "        self.training_accuracy = None\n",
    "        \n",
    "    # Function is implemented using lesson07 slides\n",
    "    def createModel(self):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Conv2D(filters = 6, kernel_size=(3,3), activation='relu', input_shape= (28,28,1)))\n",
    "        model.add(layers.AveragePooling2D())\n",
    "        model.add(layers.Conv2D(filters = 16, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(layers.AveragePooling2D())\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(units = 120, activation='relu'))\n",
    "        model.add(layers.Dense(units = 84, activation='relu'))\n",
    "        model.add(layers.Dense(units = 10, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_and_test_model(self):\n",
    "        cnn_model = self.createModel()\n",
    "        self.epoch_loss = []\n",
    "        self.epoch_accuracy = []\n",
    "        self.training_loss = []\n",
    "        self.training_accuracy = []\n",
    "\n",
    "        # Gemini code - Necessary in order to reshape data match the expected format for CNN\n",
    "        self.x_train = self.x_train.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "        self.x_test = self.x_test.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "\n",
    "        # Gemini code - Label encoding, fixes problem between model output and our own labels\n",
    "        self.y_train = keras.utils.to_categorical(self.y_train, num_classes=10)\n",
    "        self.y_test = keras.utils.to_categorical(self.y_test, num_classes=10)\n",
    "        \n",
    "        # Gemini code\n",
    "        for epoch in range(1, 21):\n",
    "            modelHistory = cnn_model.fit(self.x_train, self.y_train, epochs=1, batch_size=64, verbose=1)\n",
    "        \n",
    "            self.epoch_loss.append(modelHistory.history['loss'][0])\n",
    "            self.epoch_accuracy.append(modelHistory.history['accuracy'][0])\n",
    "                \n",
    "                \n",
    "        self.training_loss.append(self.epoch_loss)\n",
    "        self.training_accuracy.append(self.epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_acc = cnn_model.evaluate(self.x_test, self.y_test)\n",
    "        print(\"Test mean accuracy\", np.mean(test_acc))\n",
    "        print(\"Test mean loss\", np.mean(test_loss))\n",
    "        \n",
    "    # Code-structure from stack overflow\n",
    "    def plotTrainingData(self):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(np.mean(self.training_loss, axis=0), label=\"Training loss\")\n",
    "        plt.title(\"Training loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(np.mean(self.training_accuracy, axis=0), label=\"Training accuracy\")\n",
    "        plt.title(\"Training accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "newCnn = CNNModel()\n",
    "\n",
    "newCnn.train_and_test_model()\n",
    "newCnn.plotTrainingData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2021-10-20| CEF, initial version, clone from [HOML].\n",
    "2021-10-26| CEF, added learning curve item.\n",
    "2022-01-25| CEF, update to SWMAL F22.\n",
    "2023-03-08| CEF, updated page no to HOML 3rd. ed., updated to SWMAL F23.\n",
    "2023-03-15| CEF, removed wording \"from scratch\", replaced with \"via the Keras API\" and added comment about references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
